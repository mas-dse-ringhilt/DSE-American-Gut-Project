{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microbiome Embedding with word2vec\n",
    "\n",
    "In order to deal with the sparseness of the microbiome data we can attempt to use word2vec to create a dense embedding that represents each OTU. By representing each OTU as a dense vector it will be easier to use for predictive modeling later on. Data is being read from a local pkl file in this demonstration. Proper implementation will pull the data out of S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "# pull table from local file\n",
    "samples = pd.read_pickle(r'C:\\Users\\bwesterber\\Downloads\\biom_table.pkl')\n",
    "\n",
    "# replace nans with zeros\n",
    "samples = samples.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are framing this as an NLP problem lets think of each microbiome sample as a sentence and each OTU as a word. Here we construct the sentences that will be put into the word2vec model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for sample in range(len(samples) - 1):\n",
    "    try:\n",
    "        sentence = list(samples[sample][samples[sample] > 0].index)\n",
    "        sentences.append([str(x) for x in sentence])\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can augment the dataset use for generating the embeddings by shuffling each sample. In CBOW mode word order shouldnt matter for the embedding, but having a larger training set might improve how word2vec learns the conditional probability of each word. The usefullness of this is still unclear and may not be required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle each sample around and append it to the training data\n",
    "augmentation_constant = 2\n",
    "generated_sentences = []\n",
    "for sentence in sentences:\n",
    "    for augmentation in range(augmentation_constant):\n",
    "        shuffle(sentence)\n",
    "        generated_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepared data is now fed into the gensim word2vec model for training in CBOW mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27331117, 28082160)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(generated_sentences, size = 100, min_count = 2, window = 100, workers = 4, sg = 0)\n",
    "model.train(generated_sentences, total_examples = len(sentences), epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the model to see which OTUs are most similar to each other in the embedding space. The most_similar method returns the cosine similairty between the input OTU and its nearest neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('354969', 0.9211254119873047),\n",
       " ('278561', 0.5733003616333008),\n",
       " ('298273', 0.421808123588562),\n",
       " ('74035', 0.39019107818603516),\n",
       " ('128089', 0.38910770416259766),\n",
       " ('321953', 0.37498682737350464),\n",
       " ('321024', 0.3368404805660248),\n",
       " ('179973', 0.32836204767227173),\n",
       " ('104226', 0.32391905784606934),\n",
       " ('286850', 0.3225645422935486)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('84239', topn = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microbiome Embedding with Poincare Embeddings\n",
    "\n",
    "If we think of each OTU as a vertex in an undirected graph we can embed it using a Poincare embedding. Each OTU that coocurs with another in a sample will share an edge between them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
